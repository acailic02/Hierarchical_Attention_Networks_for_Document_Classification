{
 "cells": [
  {
   "cell_type": "code",
   "id": "540a6594-db27-4c14-ae9d-220d86de29fe",
   "metadata": {},
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\geass\\Hierarchical_Attention_Networks_for_Document_Classification')\n",
    "from models.HAN import HAN\n",
    "from utils import preprocessing as pp\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(r'C:\\Users\\geass\\Hierarchical_Attention_Networks_for_Document_Classification\\data\\Amazon_reviews_polarity\\train.csv')\n",
    "df.head(10)"
   ],
   "id": "d307f56b-e62b-4565-b1af-298fa8d68c1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df.columns = ['polarity', 'title', 'review']\n",
    "df = df.sample(n=10000, random_state=42)\n",
    "df['review'] = df['title'].astype(str) + '. ' + df['review'].astype(str)\n",
    "df = df.drop('title', axis=1)"
   ],
   "id": "5d4bf9d1-90c5-4d14-85ce-a0b9d8d1c7df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_train = df.sample(n=8000, random_state=42)\n",
    "\n",
    "df_train_index = df_train.index\n",
    "df = df.drop(df_train_index)\n",
    "df_valid = df.sample(n=10000, random_state=42)\n",
    "\n",
    "df_valid_index = df_valid.index\n",
    "df_test = df.drop(df_valid_index)\n",
    "\n",
    "y_train = torch.tensor(df_train['polarity'].map(lambda x: 0 if x==1 else 1).to_numpy(), dtype=torch.long)\n",
    "y_valid = torch.tensor(df_valid['polarity'].map(lambda x: 0 if x==1 else 1).to_numpy(), dtype=torch.long)\n",
    "y_test = torch.tensor(df_test['polarity'].map(lambda x: 0 if x==1 else 1).to_numpy(), dtype=torch.long)\n",
    "\n",
    "num_classes = len(torch.unique(y_train))"
   ],
   "id": "ee2bb3e2c3f39480"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tokenized_train = pp.tokenize_docs(df)\n",
    "tokenized_valid = pp.tokenize_docs(df_valid)\n",
    "tokenized_test = pp.tokenize_docs(df_test)"
   ],
   "id": "c45b571d-7299-4ebf-8888-dd4d42ccf3c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "vocabulary, word_count = pp.build_vocabulary(tokenized_train)\n",
    "\n",
    "tokenized_train = pp.replace_unk(tokenized_train, word_count)\n",
    "tokenized_valid = pp.replace_unk(tokenized_valid, word_count)\n",
    "tokenized_test = pp.replace_unk(tokenized_test, word_count)\n",
    "\n",
    "max_sentence_len = pp.max_sentence_length(tokenized_train)\n",
    "max_document_len = pp.max_document_length(tokenized_train)\n",
    "\n",
    "tokenized_train = pp.insert_padding(tokenized_train, max_sentence_len, max_document_len)\n",
    "tokenized_valid = pp.truncate(tokenized_valid, max_sentence_len, max_document_len)\n",
    "tokenized_valid = pp.insert_padding(tokenized_valid, max_sentence_len, max_document_len)\n",
    "tokenized_test = pp.truncate(tokenized_test, max_sentence_len, max_document_len)\n",
    "tokenized_test = pp.insert_padding(tokenized_test, max_sentence_len, max_document_len)\n",
    "\n",
    "embedding_matrix = pp.make_embedding_matrix(tokenized_train, vocabulary, embedding_size=100)\n",
    "x_train = pp.word_to_indices(tokenized_train, vocabulary)\n",
    "x_valid = pp.word_to_indices(tokenized_valid, vocabulary)\n",
    "x_test = pp.word_to_indices(tokenized_test, vocabulary)"
   ],
   "id": "faddf2b3-eff3-4099-af48-852ae0f0b8cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from torch.utils.data import Dataset, DataLoader",
   "id": "736babcc-5843-411a-a475-7502f93f6b9d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "36c46d4b-f5df-4bfd-b7f8-8f67b858052f",
   "metadata": {},
   "source": [
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, docs, labels):\n",
    "        self.docs = docs\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.docs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.docs[idx], self.labels[idx]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_set = ReviewDataset(x_train, y_train)\n",
    "train_dataloader = DataLoader(train_set, batch_size=256, shuffle=True, pin_memory=True)\n",
    "\n",
    "valid_set = ReviewDataset(x_valid, y_valid)\n",
    "valid_dataloader = DataLoader(valid_set, batch_size=256, pin_memory=True)\n",
    "\n",
    "test_set = ReviewDataset(x_test, y_valid)\n",
    "test_dataloader = DataLoader(test_set, batch_size=256, pin_memory=True)"
   ],
   "id": "360424ee36a32849"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ],
   "id": "6edfd39c8391fe02"
  },
  {
   "cell_type": "code",
   "id": "a29016dd-edbf-4d65-a2a0-179b204eb557",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T02:06:38.859095Z",
     "start_time": "2025-10-15T02:06:38.835527Z"
    }
   },
   "source": [
    "def train_model(model_class, model_kwargs, dataloader, criterion, optimizer_class, lr, device, epochs):\n",
    "    model = model_class(**model_kwargs).to(device)\n",
    "    optimizer = optimizer_class(model.parameters(), lr=lr)\n",
    "\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(x)\n",
    "            loss = criterion(output, y)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        losses.append(avg_loss)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    plt.plot(losses)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Average Loss\")\n",
    "    plt.title(\"Training Loss per Epoch\")\n",
    "    plt.show()\n",
    "\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T01:26:42.857523Z",
     "start_time": "2025-10-15T01:26:42.845481Z"
    }
   },
   "cell_type": "code",
   "source": "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, ConfusionMatrixDisplay",
   "id": "2a2bfe597ccae0f",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T02:04:39.093265Z",
     "start_time": "2025-10-15T02:04:39.076690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_model(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            output = model(x)\n",
    "            y_pred.extend(output.argmax(dim=1).cpu().tolist())\n",
    "            y_true.extend(y.cpu().tolist())\n",
    "            loss = criterion(output, y)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.4f}, Loss: {avg_loss:.4f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Negative\", \"Positive\"])\n",
    "    cm_display.plot()\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    return"
   ],
   "id": "6a9a76adb6e77f5",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T02:12:03.760309Z",
     "start_time": "2025-10-15T02:12:03.748734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def lr_grid_search(model_class, model_kwargs, learning_rates, dataloader, criterion, optimizer_class, device, epochs):\n",
    "\n",
    "    results = []\n",
    "    for lr in learning_rates:\n",
    "        print(f\"=============Learning rate: {lr}===========\")\n",
    "        model = train_model(model_class, model_kwargs, dataloader, criterion, optimizer_class, lr, device, epochs)\n",
    "        evaluate_model(model, test_dataloader, criterion, device)"
   ],
   "id": "bc32862667046c45",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "bbdbc77d0f88ee61",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
